{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Quora.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venkatbalineni/NLP/blob/NLP_develop/NLP_Quora_EDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "vCcTaMMxyEmm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vDAm2YTt0AJc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas.io.json import json_normalize\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "color = sns.color_palette()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nXw0Vilg0QlB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qKAMQaO10rIx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install lightgbm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bqYLd1IN0Smk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from plotly import tools\n",
        "import plotly.offline as py\n",
        "py.init_notebook_mode(connected=True)\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "from sklearn import model_selection, preprocessing, metrics, ensemble, naive_bayes, linear_model\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import lightgbm as lgb\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eNWPVYy10eFX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pd.options.mode.chained_assignment = None\n",
        "pd.options.display.max_columns = 999"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3WL4cY1m08vr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('./train.csv')\n",
        "test_df = pd.read_csv('./test_quora.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-aHnADP51RDK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train_df.head()\n",
        "train_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oea0TQkC4vhu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df['target'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dvMXsjOU46M3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cnt_srs = train_df['target'].value_counts()\n",
        "\n",
        "trace = go.Bar(\n",
        "  x = cnt_srs.index,\n",
        "  y = cnt_srs.values,\n",
        "  marker = dict(\n",
        "    color = cnt_srs.values,\n",
        "    colorscale = 'picnic',\n",
        "    reversescale = True  \n",
        "  )\n",
        ")\n",
        "\n",
        "layout = go.Layout(\n",
        "    title='Target Count',\n",
        "    font=dict(size=18)\n",
        ")\n",
        "\n",
        "data = [trace]\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "py.iplot(fig, filename=\"TargetCount\")\n",
        "\n",
        "## target distribution ##\n",
        "labels = (np.array(cnt_srs.index))\n",
        "sizes = (np.array((cnt_srs / cnt_srs.sum())*100))\n",
        "\n",
        "trace = go.Pie(labels=labels, values=sizes)\n",
        "layout = go.Layout(\n",
        "    title='Target distribution',\n",
        "    font=dict(size=18),\n",
        "    width=600,\n",
        "    height=600,\n",
        ")\n",
        "data = [trace]\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "py.iplot(fig)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VK0lGM9290zL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install wordcloud"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-F4S5do39okO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "# Thanks : https://www.kaggle.com/aashita/word-clouds-of-various-shapes ##\n",
        "def plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), \n",
        "                   title = None, title_size=40, image_color=False):\n",
        "    stopwords = set(STOPWORDS)\n",
        "    more_stopwords = {'one', 'br', 'Po', 'th', 'sayi', 'fo', 'Unknown'}\n",
        "    stopwords = stopwords.union(more_stopwords)\n",
        "\n",
        "    wordcloud = WordCloud(background_color='black',\n",
        "                    stopwords = stopwords,\n",
        "                    max_words = max_words,\n",
        "                    max_font_size = max_font_size, \n",
        "                    random_state = 42,\n",
        "                    width=800, \n",
        "                    height=400,\n",
        "                    mask = mask)\n",
        "    wordcloud.generate(str(text))\n",
        "    \n",
        "    plt.figure(figsize=figure_size)\n",
        "    if image_color:\n",
        "        image_colors = ImageColorGenerator(mask);\n",
        "        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n",
        "        plt.title(title, fontdict={'size': title_size,  \n",
        "                                  'verticalalignment': 'bottom'})\n",
        "    else:\n",
        "        plt.imshow(wordcloud);\n",
        "        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n",
        "                                  'verticalalignment': 'bottom'})\n",
        "    plt.axis('off');\n",
        "    plt.tight_layout()  \n",
        "    \n",
        "plot_wordcloud(train_df[\"question_text\"], title=\"Word Cloud of Questions\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qEujklWyGKKX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "train1_df = train_df[train_df[\"target\"]==1]\n",
        "train0_df = train_df[train_df[\"target\"]==0]\n",
        "\n",
        "def generate_ngrams(text, n_gram=1):\n",
        "    token = [token for token in text.lower().split(\" \") if token != \"\" if token not in STOPWORDS]\n",
        "    ngrams = zip(*[token[i:] for i in range(n_gram)])\n",
        "    return [\" \".join(ngram) for ngram in ngrams]\n",
        "  \n",
        "def horizontal_bar_chart(df, color):\n",
        "    trace = go.Bar(\n",
        "        y=df[\"word\"].values[::-1],\n",
        "        x=df[\"wordcount\"].values[::-1],\n",
        "        showlegend=False,\n",
        "        orientation = 'h',\n",
        "        marker=dict(\n",
        "            color=color,\n",
        "        ),\n",
        "    )\n",
        "    return trace\n",
        "  \n",
        "freq_dict = defaultdict(int)\n",
        "for sent in train0_df[\"question_text\"]:\n",
        "    for word in generate_ngrams(sent):\n",
        "        freq_dict[word] += 1\n",
        "fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
        "fd_sorted.columns = [\"word\", \"wordcount\"]\n",
        "trace0 = horizontal_bar_chart(fd_sorted.head(50), 'blue')\n",
        "\n",
        "## Get the bar chart from insincere questions ##\n",
        "freq_dict = defaultdict(int)\n",
        "for sent in train1_df[\"question_text\"]:\n",
        "    for word in generate_ngrams(sent):\n",
        "        freq_dict[word] += 1\n",
        "fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
        "fd_sorted.columns = [\"word\", \"wordcount\"]\n",
        "trace1 = horizontal_bar_chart(fd_sorted.head(50), 'blue')\n",
        "\n",
        "# Creating two subplots\n",
        "fig = tools.make_subplots(rows=1, cols=2, vertical_spacing=0.04,\n",
        "                          subplot_titles=[\"Frequent words of sincere questions\", \n",
        "                                          \"Frequent words of insincere questions\"])\n",
        "fig.append_trace(trace0, 1, 1)\n",
        "fig.append_trace(trace1, 1, 2)\n",
        "fig['layout'].update(height=1200, width=900, paper_bgcolor='rgb(233,233,233)', title=\"Word Count Plots\")\n",
        "py.iplot(fig, filename='word-plots')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8yPqSpzsHTM2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "freq_dict = defaultdict(int)\n",
        "for sent in train0_df[\"question_text\"]:\n",
        "    for word in generate_ngrams(sent,2):\n",
        "        freq_dict[word] += 1\n",
        "fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
        "fd_sorted.columns = [\"word\", \"wordcount\"]\n",
        "trace0 = horizontal_bar_chart(fd_sorted.head(50), 'orange')\n",
        "\n",
        "\n",
        "freq_dict = defaultdict(int)\n",
        "for sent in train1_df[\"question_text\"]:\n",
        "    for word in generate_ngrams(sent,2):\n",
        "        freq_dict[word] += 1\n",
        "fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
        "fd_sorted.columns = [\"word\", \"wordcount\"]\n",
        "trace1 = horizontal_bar_chart(fd_sorted.head(50), 'orange')\n",
        "\n",
        "# Creating two subplots\n",
        "fig = tools.make_subplots(rows=1, cols=2, vertical_spacing=0.04,horizontal_spacing=0.15,\n",
        "                          subplot_titles=[\"Frequent bigrams of sincere questions\", \n",
        "                                          \"Frequent bigrams of insincere questions\"])\n",
        "fig.append_trace(trace0, 1, 1)\n",
        "fig.append_trace(trace1, 1, 2)\n",
        "fig['layout'].update(height=1200, width=900, paper_bgcolor='rgb(233,233,233)', title=\"Bigram Count Plots\")\n",
        "py.iplot(fig, filename='word-plots')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UyWnHu6ALPaX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "freq_dict = defaultdict(int)\n",
        "for sent in train0_df[\"question_text\"]:\n",
        "    for word in generate_ngrams(sent,3):\n",
        "        freq_dict[word] += 1\n",
        "fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
        "fd_sorted.columns = [\"word\", \"wordcount\"]\n",
        "trace0 = horizontal_bar_chart(fd_sorted.head(50), 'green')\n",
        "\n",
        "\n",
        "freq_dict = defaultdict(int)\n",
        "for sent in train1_df[\"question_text\"]:\n",
        "    for word in generate_ngrams(sent,3):\n",
        "        freq_dict[word] += 1\n",
        "fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
        "fd_sorted.columns = [\"word\", \"wordcount\"]\n",
        "trace1 = horizontal_bar_chart(fd_sorted.head(50), 'green')\n",
        "\n",
        "# Creating two subplots\n",
        "fig = tools.make_subplots(rows=1, cols=2, vertical_spacing=0.04, horizontal_spacing=0.2,\n",
        "                          subplot_titles=[\"Frequent trigrams of sincere questions\", \n",
        "                                          \"Frequent trigrams of insincere questions\"])\n",
        "fig.append_trace(trace0, 1, 1)\n",
        "fig.append_trace(trace1, 1, 2)\n",
        "fig['layout'].update(height=1200, width=1200, paper_bgcolor='rgb(233,233,233)', title=\"Trigram Count Plots\")\n",
        "py.iplot(fig, filename='word-plots')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yfFO7uFPLiYN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df[\"num_words\"] = train_df[\"question_text\"].apply(lambda x: len(str(x).split()))\n",
        "test_df[\"num_words\"] = test_df[\"question_text\"].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "## Number of unique words in the text ##\n",
        "train_df[\"num_unique_words\"] = train_df[\"question_text\"].apply(lambda x: len(set(str(x).split())))\n",
        "test_df[\"num_unique_words\"] = test_df[\"question_text\"].apply(lambda x: len(set(str(x).split())))\n",
        "\n",
        "## Number of characters in the text ##\n",
        "train_df[\"num_chars\"] = train_df[\"question_text\"].apply(lambda x: len(str(x)))\n",
        "test_df[\"num_chars\"] = test_df[\"question_text\"].apply(lambda x: len(str(x)))\n",
        "\n",
        "## Number of stopwords in the text ##\n",
        "train_df[\"num_stopwords\"] = train_df[\"question_text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\n",
        "test_df[\"num_stopwords\"] = test_df[\"question_text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\n",
        "\n",
        "## Number of punctuations in the text ##\n",
        "train_df[\"num_punctuations\"] =train_df['question_text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
        "test_df[\"num_punctuations\"] =test_df['question_text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
        "\n",
        "## Number of title case words in the text ##\n",
        "train_df[\"num_words_upper\"] = train_df[\"question_text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
        "test_df[\"num_words_upper\"] = test_df[\"question_text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
        "\n",
        "## Number of title case words in the text ##\n",
        "train_df[\"num_words_title\"] = train_df[\"question_text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
        "test_df[\"num_words_title\"] = test_df[\"question_text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
        "\n",
        "## Average length of the words in the text ##\n",
        "train_df[\"mean_word_len\"] = train_df[\"question_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
        "test_df[\"mean_word_len\"] = test_df[\"question_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z8lG1J4vLujK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Truncate some extreme values for better visuals ##\n",
        "train_df['num_words'].loc[train_df['num_words']>60] = 60 #truncation for better visuals\n",
        "train_df['num_punctuations'].loc[train_df['num_punctuations']>10] = 10 #truncation for better visuals\n",
        "train_df['num_chars'].loc[train_df['num_chars']>350] = 350 #truncation for better visuals\n",
        "\n",
        "f, axes = plt.subplots(3, 1, figsize=(10,20))\n",
        "sns.boxplot(x='target', y='num_words', data=train_df, ax=axes[0])\n",
        "axes[0].set_xlabel('Target', fontsize=12)\n",
        "axes[0].set_title(\"Number of words in each class\", fontsize=15)\n",
        "\n",
        "sns.boxplot(x='target', y='num_chars', data=train_df, ax=axes[1])\n",
        "axes[1].set_xlabel('Target', fontsize=12)\n",
        "axes[1].set_title(\"Number of characters in each class\", fontsize=15)\n",
        "\n",
        "sns.boxplot(x='target', y='num_punctuations', data=train_df, ax=axes[2])\n",
        "axes[2].set_xlabel('Target', fontsize=12)\n",
        "#plt.ylabel('Number of punctuations in text', fontsize=12)\n",
        "axes[2].set_title(\"Number of punctuations in each class\", fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_WRJimw4MEex",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get the tfidf vectors #\n",
        "tfidf_vec = TfidfVectorizer(stop_words='english', ngram_range=(1,3))\n",
        "tfidf_vec.fit_transform(train_df['question_text'].values.tolist() + test_df['question_text'].values.tolist())\n",
        "train_tfidf = tfidf_vec.transform(train_df['question_text'].values.tolist())\n",
        "test_tfidf = tfidf_vec.transform(test_df['question_text'].values.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "227-D5gaMJDO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_y = train_df[\"target\"].values\n",
        "\n",
        "def runModel(train_X, train_y, test_X, test_y, test_X2):\n",
        "    model = linear_model.LogisticRegression(C=5., solver='sag')\n",
        "    model.fit(train_X, train_y)\n",
        "    pred_test_y = model.predict_proba(test_X)[:,1]\n",
        "    pred_test_y2 = model.predict_proba(test_X2)[:,1]\n",
        "    return pred_test_y, pred_test_y2, model\n",
        "\n",
        "print(\"Building model.\")\n",
        "cv_scores = []\n",
        "pred_full_test = 0\n",
        "pred_train = np.zeros([train_df.shape[0]])\n",
        "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\n",
        "for dev_index, val_index in kf.split(train_df):\n",
        "    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\n",
        "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
        "    pred_val_y, pred_test_y, model = runModel(dev_X, dev_y, val_X, val_y, test_tfidf)\n",
        "    pred_full_test = pred_full_test + pred_test_y\n",
        "    pred_train[val_index] = pred_val_y\n",
        "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mmJnFP7RMbU7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for thresh in np.arange(0.1, 0.201, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_val_y>thresh).astype(int))))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WIvy-6rDNe-M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install eli5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PKiDbjatMiiP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import eli5\n",
        "eli5.show_weights(model, vec=tfidf_vec, top=100, feature_filter=lambda x: x != '<BIAS>')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}